{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPED data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Load data](#Load-data)\n",
    "2. [Tempalte matching](#Template-matching)\n",
    "    1. [Build template library](#Build-the-template-library)\n",
    "    2. [Indexing](#Indexing)\n",
    "3. [NMF](#NMF)\n",
    "4. [Clustering](#Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might have tk installed instead of qt\n",
    "%matplotlib qt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyxem as pxm\n",
    "\n",
    "import diffpy.structure\n",
    "\n",
    "from transforms3d.axangles import axangle2mat\n",
    "from transforms3d.euler import axangle2euler\n",
    "from transforms3d.euler import euler2mat\n",
    "from transforms3d.euler import mat2euler\n",
    "\n",
    "#import warnings\n",
    "# Silence some future warnings and user warnings (float64 -> uint8)\n",
    "# in skimage when calling remove_background with h-dome (below)\n",
    "# Should really be fixed elsewhere.\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SPED dataset. The file is lazy-loaded and then cut. This ensures that only required areas are loaded from disk to memory.\n",
    "\n",
    "The data type is changed to float and some metadata is set. The call to `pxm.ElectronDiffraction` converts the lazy hyperspy signal to a fully loaded pyxem object which gives access to the pyxem tools. The metadata from the file has to be copied manually. The constructor probably should have done so automatically, but it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/Dokumenter/MTNANO/Prosjektoppgave/SPED_data_GaAs_NW/'\n",
    "in_file = data_dir + 'gen/Julie_180510_SCN45_FIB_a_pyxem_sample.hdf5'\n",
    "reciprocal_angstrom_per_pixel = 0.032  # Reciprocal calibration\n",
    "\n",
    "dp = pxm.load(in_file, lazy=True)\n",
    "dp = dp.inav[95:100, 30:75]\n",
    "\n",
    "# The background removal and affine transform changes the type without\n",
    "# respecting the loaded precission. We do it ourselves to be explicit.\n",
    "if dp.data.dtype != 'float64':\n",
    "    dp.change_dtype('float64')\n",
    "    \n",
    "# Convert to a pyxem ElectronDiffraction, conserve the metadata and add some more\n",
    "dp_metadata = dp.metadata\n",
    "dp = pxm.ElectronDiffraction(dp)\n",
    "dp.data *= 1 / dp.data.max()\n",
    "dp.metadata = dp_metadata\n",
    "dp.set_diffraction_calibration(reciprocal_angstrom_per_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34cc5dcfbcc48309317e1552255661c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=225), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19586de3025940b9b825656ca7e757fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=225), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scale_x = 0.9954344818525674\n",
    "scale_y = 1.0314371455342144\n",
    "offset_x = 0.6312060246018557\n",
    "offset_y = -0.3516223696556279\n",
    "sigma_min = 2\n",
    "sigma_max = 8\n",
    "\n",
    "dp.apply_affine_transformation(np.array([\n",
    "    [scale_x, 0, offset_x],\n",
    "    [0, scale_y, offset_y],\n",
    "    [0, 0, 1]\n",
    "    ]))\n",
    "dp = dp.remove_background('gaussian_difference', sigma_min=sigma_min, sigma_max=sigma_max)\n",
    "dp.data *= 1 / dp.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching\n",
    "Template matching generates a database of simulated diffraction patterns and then compares all simulated diffraction pattern to each of the experimental diffraction patterns to find the best match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyxem.generators.indexation_generator import IndexationGenerator\n",
    "from pyxem.generators.structure_library_generator import StructureLibraryGenerator\n",
    "from pyxem.libraries.diffraction_library import load_DiffractionLibrary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the template library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load structure files using `diffpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_zb_file = r'D:\\Dokumenter\\MTNANO\\Prosjektoppgave\\Data\\Gen\\NN_test_data\\GaAs_mp-2534_conventional_standard.cif'\n",
    "structure_wz_file = r'D:\\Dokumenter\\MTNANO\\Prosjektoppgave\\Data\\Gen\\NN_test_data\\GaAs_mp-8883_conventional_standard.cif'\n",
    "\n",
    "structure_zb = diffpy.structure.loadStructure(structure_zb_file)\n",
    "structure_wz = diffpy.structure.loadStructure(structure_wz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_list_resolution = np.deg2rad(1)\n",
    "beam_energy_keV = 200\n",
    "max_excitation_error = 1/6.84  # Ångström^{-1}, extent of relrods in reciprocal space. Inverse of specimen thickness is a starting point\n",
    "\n",
    "phase_descriptions = [('ZB', structure_zb, 'cubic'),\n",
    "                      ('WZ', structure_wz, 'hexagonal')]\n",
    "phase_names = [phase[0] for phase in phase_descriptions]\n",
    "structure_library_generator = StructureLibraryGenerator(phase_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load diffraction library from file on disk or create a new one. From disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffraction_library_cache_filename = '../../Data/Runs/tmp/GaAs_cubic_hex_1deg.pickle'\n",
    "diffraction_library = load_DiffractionLibrary(diffraction_library_cache_filename, safety=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or generate if from a rotation list on a stereographic triangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inplane_rotations = [np.deg2rad((103, 173)), np.deg2rad((140,))]\n",
    "structure_library = structure_library_generator.get_orientations_from_stereographic_triangle(\n",
    "        inplane_rotations, rotation_list_resolution)\n",
    "gen = pxm.DiffractionGenerator(beam_energy_keV, max_excitation_error=max_excitation_error)\n",
    "library_generator = pxm.DiffractionLibraryGenerator(gen)\n",
    "target_pattern_dimension_pixels = dp.axes_manager.signal_shape[0]\n",
    "half_pattern_size = target_pattern_dimension_pixels // 2\n",
    "reciprocal_radius = reciprocal_angstrom_per_pixel*(half_pattern_size - 1)\n",
    "diffraction_library = library_generator.get_diffraction_library(\n",
    "    structure_library,\n",
    "    calibration=reciprocal_angstrom_per_pixel,\n",
    "    reciprocal_radius=reciprocal_radius,\n",
    "    half_shape=(half_pattern_size, half_pattern_size),\n",
    "    with_direct_beam=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, save the library for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffraction_library.pickle_library(diffraction_library_cache_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Given the `diffraction_library` defined above, the `IndexationGenerator` finds the correlation between all patterns in the library and each experimental pattern, and returns the `n_largest` matches with highest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = IndexationGenerator(dp, diffraction_library)\n",
    "indexation_results = indexer.correlate(n_largest=4, keys=phase_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyxem has exposes visualisations for the indexation results through a `CrystallographicMap`. Here, the phase map and orientation maps are plotted along with reliability maps. The orientation maps are not really usable directly, and should be exported to mtex for better plotting, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal_map = indexation_results.get_crystallographic_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal_map.get_phase_map().plot()\n",
    "crystal_map.get_reliability_map_phase().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal_map.get_orientation_map().plot()\n",
    "crystal_map.get_reliability_map_orientation().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mtex gives much better orientation maps, and pyxem supports exporting the orientation data in a format that can be read by mtex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal_map.save_mtex_map(r'..\\..\\Data\\Runs\\tmp\\mtex_orientation_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the best match. For now, single position at a time. The pyxem solution (`indexation_results.plot_best_matching_results_on_signal(dp, phase_names, diffraction_library)`) does not work for non-square datasets. This is a `Hyperspy` problem, see \n",
    "https://github.com/hyperspy/hyperspy/issues/2080. Instead, first get the matches and store them in peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = []\n",
    "for indexation_result in indexation_results:\n",
    "    single_match_result = indexation_result.data\n",
    "    best_fit = single_match_result[np.argmax(single_match_result[:, 4])]\n",
    "    phase_name = phase_names[int(best_fit[0])]\n",
    "    library_entry = diffraction_library.get_library_entry(phase=phase_name, angle=(best_fit[1], best_fit[2], best_fit[3]))\n",
    "    peaks.append((library_entry['pixel_coords'], library_entry['intensities'], [phase_name, *best_fit[1:4]], best_fit[4]))\n",
    "peaks = np.array(peaks).reshape(dp.data.shape[0], dp.data.shape[1], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, plot the image and write the phase and angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.set_diffraction_calibration(reciprocal_angstrom_per_pixel)\n",
    "x = 0\n",
    "y = 34\n",
    "plt.figure('Best fit')\n",
    "plt.cla()\n",
    "plt.imshow(dp.inav[x, y])\n",
    "plt.scatter(peaks[y, x, 0][:, 0], peaks[y, x, 0][:, 1], marker='x', c=np.log(1 + peaks[y, x, 1]), cmap='autumn_r')\n",
    "print('Best fit:', peaks[y, x, 2], 'score:', peaks[y, x, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative matrix factorisation factorises the dataset into `n_components` components that, hopefully, resemble physical diffraction patterns. This requires finding the correct number of components. It might help to study the Skree plot, but with long tails, the cut-off might not be clear. The decomposition used to create the Skree plot is not the same that is used in NMF, and NMF will not give the same separation between noise and signal, but often separates the dataset by other differences, such as bending or strain, if too many components are given. Too few components might combine similar areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cab13332e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.decomposition(normalize_poissonian_noise=True, algorithm='svd')\n",
    "dp.plot_explained_variance_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of components and to the decomposition. `normalize_poissonian_noise=True` seems to give better results when there is noise present, but it might be worth testing without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.decomposition(\n",
    "        normalize_poissonian_noise=True,\n",
    "        algorithm='nmf',\n",
    "        output_dimension=n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperspy conveniently provides a function to visualise the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c275744e0e4b0db5c6dc3f706813bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simho\\AppData\\Local\\conda\\conda\\envs\\tem\\lib\\site-packages\\matplotlib\\tight_layout.py:177: UserWarning: The left and right margins cannot be made large enough to accommodate all axes decorations. \n",
      "  warnings.warn('The left and right margins cannot be made large '\n"
     ]
    }
   ],
   "source": [
    "dp.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can get the decomposition data directly if we want to do some further processing on it. Here, we also normalise each loading to have a maximum value of 1 to remove a disambiguity in the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results\n",
    "factors = dp.get_decomposition_factors().data\n",
    "loadings = dp.get_decomposition_loadings().data\n",
    "\n",
    "# Factorization is only unique to a constant factor.\n",
    "# Scale so that each loading has a maximum value of 1.\n",
    "scaling = loadings.max(axis=(1, 2))  # Maximum in each component\n",
    "factors *= scaling[:, np.newaxis, np.newaxis]\n",
    "loadings *= np.reciprocal(scaling)[:, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is often used to group similar data points. To allow clustering, the data points (here, the diffraction patterns, represented as $\\sim 10^4$ dimensions) has to be reduced to a lower-dimensional space. Here, we use the UMAP algorithm. Clustering is done with HDBSCAN. Plenty of other options exist, but the combination of dimensionality reduction and clustering is general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap  # conda install -c conda-forge umap-learn, pip install umap-learn, or similar\n",
    "import hdbscan  # conda install hdbscan, pip install hdbscan, or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering depends on quite a few parameters, which we set here. Most important is `n_neighbours` and `cluster_min_size`. Only the UMAP embedding takes time to calculate, so the HDBSCAN paramters are easier to optimise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed to get reproducible results. Set to None to get a new number each time\n",
    "random_seed = 42\n",
    "\n",
    "# Number of dimensions to reduce to before clustering. 2 allows easy visualisation, higher (~10) might give\n",
    "# more accurate results.\n",
    "n_dimensions = 2\n",
    "\n",
    "# Number of nearest neighbours to check. Higher values (relative to the number of diffraction patterns)\n",
    "# gives a better global clustering (position of clusters relative to each other are more representative\n",
    "# of similarity), while lower values gives better positioning within clusters.\n",
    "# See https://umap-learn.readthedocs.io/en/latest/parameters.html#n-neighbors\n",
    "n_neighbours = 20\n",
    "\n",
    "# Minimum distance in the embedding, [0, 1], typically 0.0 for clustering, but close to 1 allows fuzzy clustering.\n",
    "# See https://umap-learn.readthedocs.io/en/latest/parameters.html#min-dist\n",
    "min_dist = 0.0\n",
    "\n",
    "# How conservative the clustering is. Larger numbers assigns more points as noise.\n",
    "# See https://hdbscan.readthedocs.io/en/latest/parameter_selection.html#selecting-min-samples\n",
    "cluster_min_samples = 1\n",
    "\n",
    "# Smallest grouping to consider a cluster.\n",
    "# See https://hdbscan.readthedocs.io/en/latest/parameter_selection.html#selecting-min-cluster-size\n",
    "cluster_min_size = 20\n",
    "\n",
    "# Reshape to a two-dimensional matrix, one row per diffraction pattern,\n",
    "# as required by UMAP\n",
    "data_flat = dp.data.reshape(-1, dp.axes_manager.signal_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding can be saved (below), and later loaded to test different cluster (HDBSCAN) parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_filename = r'..\\..\\Data\\Runs\\tmp\\umap_embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.load(embedding_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not loaded, run the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simho\\AppData\\Local\\conda\\conda\\envs\\tem\\lib\\site-packages\\umap\\spectral.py:229: UserWarning: Embedding 2 connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    }
   ],
   "source": [
    "# Do the projection to a lower dimensional space (given by 'n_dimensions')\n",
    "# using UMAP with the parameters specified above.\n",
    "embedding = umap.UMAP(\n",
    "    n_neighbors =n_neighbours,\n",
    "    min_dist    =min_dist,\n",
    "    n_components=n_dimensions,\n",
    "    random_state=random_seed,\n",
    ").fit_transform(data_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally save the embedding, since this is the most expensive step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(embedding_filename, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the low-dimensional data using HDBSCAN and the parameters specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_samples=cluster_min_samples,\n",
    "    min_cluster_size=cluster_min_size,\n",
    ").fit(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP is working on its own visualisation tools, but for now, we can create them ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_results(clusterer, embedding, dp, show_probability=True):\n",
    "    fig, (ax_scatter, ax_phases, ax_diffraction) = plt.subplots(nrows=1, ncols=3)\n",
    "    \n",
    "    ax_scatter.set_title('Projection')\n",
    "    color_palette = sns.color_palette(n_colors=clusterer.labels_.max() + 1)\n",
    "    #color_palette = sns.color_palette('Paired', n_colors=clusterer.labels_.max() + 1)\n",
    "    cluster_colors = [color_palette[l] if l >= 0\n",
    "                      else (0.3, 0.3, 0.3)\n",
    "                      for l in clusterer.labels_]\n",
    "    cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                             zip(cluster_colors, clusterer.probabilities_)]\n",
    "    \n",
    "    ax_scatter.scatter(*embedding.T, s=30, c=cluster_member_colors,\n",
    "                       alpha=0.25,\n",
    "                       picker=True)\n",
    "    ax_scatter.tick_params(\n",
    "        axis='both',\n",
    "        which='both',\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelleft=False,\n",
    "        labelright=False,\n",
    "        labelbottom=False)\n",
    "\n",
    "    ax_phases.set_title('Phases')\n",
    "    phase_map = np.empty((dp.axes_manager.navigation_size, 3))\n",
    "    \n",
    "    nav_width, nav_height = dp.axes_manager.navigation_shape\n",
    "    \n",
    "    for i, (label, probability) in enumerate(zip(clusterer.labels_, clusterer.probabilities_)):\n",
    "        cluster_color = color_palette[label]\n",
    "        phase_map[i] = sns.desaturate(cluster_color, probability) if show_probability else cluster_color\n",
    "    ax_phases.imshow(phase_map.reshape(nav_height, nav_width, 3), picker=True)\n",
    "    \n",
    "    def update_diffraction_pattern(x, y):\n",
    "        ax_diffraction.set_title(\n",
    "            'Diffraction pattern from {}/{}, {}/{}'.format(\n",
    "                x, dp.axes_manager.navigation_shape[0],\n",
    "                y, dp.axes_manager.navigation_shape[1]))\n",
    "        ax_diffraction.imshow(dp.inav[x, y])\n",
    "        ax_diffraction.figure.canvas.draw_idle()\n",
    "        \n",
    "    update_diffraction_pattern(0, 0)\n",
    "    \n",
    "    current_annotation = None\n",
    "    def annotate(x, y, pos):\n",
    "        nonlocal current_annotation\n",
    "        if current_annotation is not None:\n",
    "                current_annotation.remove()\n",
    "        current_annotation = ax_scatter.annotate(\n",
    "            '{}, {}'.format(x, y),\n",
    "            pos,\n",
    "            xytext=(pos[0] + 2, pos[1] + 2),\n",
    "            arrowprops = {'arrowstyle': '->'})\n",
    "        \n",
    "    def pick_handler(event):\n",
    "        if isinstance(event.artist, matplotlib.image.AxesImage):\n",
    "            x = int(round(event.mouseevent.xdata))\n",
    "            y = int(round(event.mouseevent.ydata))\n",
    "            annotate(x, y, embedding[np.ravel_multi_index((y, x), (nav_height, nav_width))])\n",
    "            update_diffraction_pattern(x, y)\n",
    "        elif isinstance(event.artist, matplotlib.collections.PathCollection):\n",
    "            picked_index = event.ind[0]\n",
    "            x, y = np.unravel_index(picked_index, dp.axes_manager.navigation_shape)\n",
    "            annotate(x, y, embedding[picked_index])\n",
    "            update_diffraction_pattern(x, y)\n",
    "        \n",
    "    fig.canvas.mpl_connect('pick_event', pick_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_dimensions == 2:\n",
    "    plottable_embedding = embedding\n",
    "else:\n",
    "    # To allow visualisation, create an extra embedding in 2D, but keep\n",
    "    # using the colours (cluster labels) from the higher-dimensional embedding\n",
    "    plottable_embedding = umap.UMAP(\n",
    "        n_neighbors =n_neighbours,\n",
    "        min_dist    =min_dist,\n",
    "        n_components=2,\n",
    "        random_state=random_seed,\n",
    "    ).fit_transform(data_flat)\n",
    "    \n",
    "plot_clustering_results(clusterer, plottable_embedding, dp, show_probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also construct loadings and factors from the cluster labels and probabilities returned by HDBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space for the results\n",
    "label_count = clusterer.labels_.max() + 1  # include 0\n",
    "cluster_factors = np.empty((label_count, signal_width, signal_height))\n",
    "cluster_loadings = np.empty((label_count, nav_width, nav_height))\n",
    "\n",
    "for label in range(label_count):\n",
    "    # Set the loading from all the HDBSCAN probabilities,\n",
    "    loadings[label] = clusterer.probabilities_.reshape(*dp.axes_manager.navigation_shape)\n",
    "    # but mask out the results not matching this label\n",
    "    mask = (clusterer.labels_ == label).reshape(*dp.axes_manager.navigation_shape)\n",
    "    loadings[label][~mask] = 0.0\n",
    "    # Calculate factors as a weighted average of cluster members\n",
    "    # and reshape to the correct shape\n",
    "    factors[label] = np.average(\n",
    "        data_flat,\n",
    "        weights=loadings[label].ravel(),\n",
    "        axis=0).reshape(*dp.axes_manager.signal_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
